{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import chromedriver_autoinstaller\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "import random\n",
    "\n",
    "sleep_time = random.uniform(1, 2)\n",
    "\n",
    "\n",
    "# 크롬 디버거로 크롬 구동\n",
    "subprocess.Popen(r'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe --remote-debugging-port=9222 --user-data-dir=\"C:\\chrometemp\"')\n",
    "time.sleep(3)  # 크롬이 완전히 실행될 때까지 대기\n",
    "\n",
    "# 웹드라이버 설정\n",
    "chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]\n",
    "driver_path = f'./{chrome_ver}/chromedriver.exe'\n",
    "option = Options()\n",
    "option.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome(driver_path, options=option)\n",
    "except:\n",
    "    chromedriver_autoinstaller.install(True)\n",
    "    driver = webdriver.Chrome(driver_path, options=option)\n",
    "\n",
    "driver.implicitly_wait(5)  # 웹 자원 로드를 위해 5초까지 기다림\n",
    "\n",
    "input(\"홈페이지 접속하면 ENTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# CSV 파일을 읽어 DataFrame으로 로드합니다.\n",
    "file_path = 'datasets.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'Date' 칼럼을 datetime 타입으로 변환합니다.\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 사용자로부터 시작 날짜와 종료 날짜를 입력받습니다.\n",
    "start_date_input = input(\"시작 날짜를 입력하세요 (YYYY-MM-DD): \")\n",
    "end_date_input = input(\"종료 날짜를 입력하세요 (YYYY-MM-DD): \")\n",
    "\n",
    "# 입력받은 날짜 문자열을 datetime 객체로 변환합니다.\n",
    "start_date = datetime.strptime(start_date_input, '%Y-%m-%d')\n",
    "end_date = datetime.strptime(end_date_input, '%Y-%m-%d')\n",
    "\n",
    "# 지정된 날짜 범위로 데이터를 필터링합니다.\n",
    "filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "# 필터링된 DataFrame에서 'Date' 칼럼만 추출하여 리스트로 변환합니다.\n",
    "formatted_date_list = filtered_df['Date'].dt.strftime('%Y%m%d').tolist()\n",
    "\n",
    "# 결과 확인을 위해 상위 5개 날짜를 출력합니다.\n",
    "print(formatted_date_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np  # NaN 처리를 위해 import\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "# 결과를 저장할 DataFrame 생성. 초기에는 'Date' 칼럼만 있는 상태입니다.\n",
    "result_df = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "# 찾고자 하는 문자열 리스트\n",
    "target_strings = [\n",
    "    '코스피 200', '코스피 200 건설', '코스피 200 중공업', '코스피 200 철강/소재',\n",
    "    '코스피 200 에너지/화학', '코스피 200 정보기술',\n",
    "    '코스피 200 금융', '코스피 200 생활소비재', '코스피 200 경기소비재'\n",
    "]\n",
    "\n",
    "# 각 문자열에 대해 칼럼을 추가합니다.\n",
    "for idx, _ in enumerate(target_strings, start=1):\n",
    "    result_df[f\"{idx}_PER\"] = None\n",
    "    result_df[f\"{idx}_PBR\"] = None\n",
    "\n",
    "# 오류 로그를 저장할 리스트\n",
    "error_log = []\n",
    "\n",
    "def click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath):\n",
    "    for date_str in formatted_date_list:\n",
    "        try:\n",
    "            # 날짜 입력 필드 찾기\n",
    "            date_input = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, input_xpath)))\n",
    "            # 날짜 입력 필드에 값 입력\n",
    "            date_input.clear()\n",
    "            date_input.send_keys(date_str)\n",
    "            \n",
    "            # 검색 버튼 클릭\n",
    "            search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "            search_button.click()\n",
    "            time.sleep(5)  # 페이지 로딩을 위해 잠시 대기\n",
    "            \n",
    "            # 데이터 추출 및 저장\n",
    "            extract_and_save_data(driver, date_str)\n",
    "            \n",
    "            # CSV 파일로 저장하고 상태를 출력합니다.\n",
    "            result_df.to_csv('2014_result.csv', index=False)\n",
    "            print(f\"{date_str} - Data has been successfully saved to interim_result.csv\")\n",
    "            \n",
    "        except Exception as e:  # 모든 예외를 포착합니다.\n",
    "            print(f\"Error with date {date_str}: {e}\")\n",
    "            error_log.append(f\"Error with date {date_str}: {e}\")\n",
    "            \n",
    "            # CSV 파일로 저장하고 상태를 출력합니다.\n",
    "            result_df.to_csv('interim_result.csv', index=False)\n",
    "            print(f\"{date_str} - Data has been successfully saved to interim_result.csv despite the error\")\n",
    "\n",
    "def extract_and_save_data(driver, date_str):\n",
    "    # 현재 페이지의 소스를 가져옵니다.\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup 객체를 생성합니다.\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # 결과를 임시로 저장할 딕셔너리\n",
    "    result_dict = {\"Date\": date_str}\n",
    "    \n",
    "    # 각 문자열에 대해 처리합니다.\n",
    "    for idx, target_string in enumerate(target_strings, start=1):\n",
    "        # 문자열을 포함하는 td 태그를 찾기\n",
    "        target_td = soup.find('td', string=target_string)\n",
    "        \n",
    "        if target_td:\n",
    "            # target_td의 형제들 중에서 data-bind=\"WT_PER\"와 \"WT_STKPRC_NETASST_RTO\" 속성을 가진 태그의 텍스트를 추출\n",
    "            per_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_PER'})\n",
    "            pbr_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_STKPRC_NETASST_RTO'})\n",
    "            \n",
    "            if per_tag and pbr_tag:\n",
    "                try:\n",
    "                    PER = float(per_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PER = np.nan  # NaN으로 설정\n",
    "                \n",
    "                try:\n",
    "                    PBR = float(pbr_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PBR = np.nan  # NaN으로 설정\n",
    "                \n",
    "                # 결과 딕셔너리에 값 추가\n",
    "                result_dict[f\"{idx}_PER\"] = PER\n",
    "                result_dict[f\"{idx}_PBR\"] = PBR\n",
    "            else:\n",
    "                print(f\"{date_str} 날짜, {target_string}에 대한 필요한 태그를 찾지 못했습니다.\")\n",
    "        else:\n",
    "            print(f\"{date_str} 날짜에 {target_string} 문자열을 포함하는 태그를 찾지 못했습니다.\")\n",
    "    \n",
    "    # 결과 DataFrame에 행을 추가합니다.\n",
    "    result_df.loc[len(result_df)] = result_dict\n",
    "\n",
    "# 함수 호출\n",
    "input_xpath = '//input[@id=\"trdDd\"]'\n",
    "search_button_xpath = '//*[@id=\"jsSearchButton\"]'\n",
    "click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath)\n",
    "\n",
    "# 결과 DataFrame 출력\n",
    "print(result_df)\n",
    "\n",
    "# 오류 로그 출력\n",
    "print(error_log)\n",
    "\n",
    "# 최종 결과를 CSV 파일로 저장\n",
    "result_df.to_csv('2014_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
