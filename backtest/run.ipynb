{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     from pandas.compat import (\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pyright: ignore[reportUnusedImport] # noqa: F401,E501\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompressors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m from pandas.compat.pyarrow import (\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_nlv\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_min_numpy_ver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;34mf\"this version of pandas is incompatible with numpy < {_min_numpy_ver}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.22.4\nyour numpy version is 1.21.5.\nPlease upgrade numpy to >= 1.22.4 to use this pandas version",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16768\\4228725554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#KS200, 기본 코드, overfitting, Train_test_split, cv = TimeSeriesSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_err\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0m_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;34mf\"C extension: {_module} not built. If you want to import \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "#KS200, 기본 코드, overfitting, Train_test_split, cv = TimeSeriesSplit\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# 데이터 불러오기 및 전처리\n",
    "model_data = pd.read_csv('../main/ks200.csv', encoding='utf-8')\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "model_data['레이블'] = encoder.fit_transform(model_data['레이블'])\n",
    "\n",
    "# 날짜 처리 및 정렬\n",
    "model_data['날짜'] = pd.to_datetime(model_data['날짜'])\n",
    "model_data.set_index('날짜', inplace=True)\n",
    "model_data.sort_index(inplace=True)\n",
    "\n",
    "# 특성과 레이블 분리\n",
    "X = model_data.drop(columns=['레이블'])\n",
    "y = model_data['레이블']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 모델 초기화 및 하이퍼파라미터 그리드 정의\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=42)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 500],\n",
    "    'max_leaf_nodes': [20, 30, 40, 50],\n",
    "    'max_features': [1, 2, 3],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "time_split_cv = TimeSeriesSplit(n_splits=10)\n",
    "rnd_search = RandomizedSearchCV(rnd_clf, param_dist_rf, cv=time_split_cv, random_state =42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델 선택 및 훈련\n",
    "best_clf = rnd_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "train_score = best_clf.score(X_train, y_train)\n",
    "test_score = best_clf.score(X_test, y_test)\n",
    "\n",
    "# 10-fold cross-validation의 정확도 계산\n",
    "cv_scores = cross_val_score(best_clf, X_train, y_train, cv=time_split_cv, scoring='accuracy')\n",
    "cv_mean_score = cv_scores.mean()\n",
    "\n",
    "# label encoding된 값 찾기\n",
    "up = encoder.transform(['up'])[0]\n",
    "neutral = encoder.transform(['neutral'])[0]\n",
    "down = encoder.transform(['down'])[0]\n",
    "\n",
    "# 혼동 행렬 확인\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred, labels=[up, neutral, down])\n",
    "y_all_pred = best_clf.predict(X)\n",
    "cm_all = confusion_matrix(y, y_all_pred, labels=[up, neutral, down])\n",
    "\n",
    "\n",
    "# 특성 중요도 확인\n",
    "feature_importance = list(zip(X_train.columns, best_clf.feature_importances_))\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(best_clf, \"separation22.pkl\")\n",
    "\n",
    "# 10. backtesting용 과거의 예측데이터 생성\n",
    "y_prediction = rnd_clf.predict(X) \n",
    "y_pred = pd.Series(y_prediction, index=y.index) \n",
    "\n",
    "# 결과 출력\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(f\"{rnd_search.best_params_}\\n\")\n",
    "print(\"<10-fold cross-validation>\")\n",
    "print(\"accuracy score mean: \", cv_mean_score)\n",
    "print(\"\\n<AI model: machine learning done >\")\n",
    "print(\"accuracy_score of train data(0.8 of sample): \", train_score)\n",
    "print(\"accuracy_score of test data(0.2 of sample): \", test_score)\n",
    "print(\"\\n<Confusion matrix>\")\n",
    "print(\"(of test)\")\n",
    "print(\"up\", \"neutral\", \"down\")\n",
    "print(cm_test)\n",
    "print(\"(of all)\")\n",
    "print(\"up\", \"neutral\", \"down\")\n",
    "print(cm_all)\n",
    "# <Feature importance>를 내림차순으로 정렬하여 출력\n",
    "print(\"\\n<Feature importance>\")\n",
    "sorted_feature_importance = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "for name, score in sorted_feature_importance:\n",
    "    print(name, \": \", score)\n",
    "\n",
    "print(\"\\n< AI model: save >\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (585) does not match length of index (150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26416\\3412175984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# 매월말에 예측했던 투자의견을 가져옴. 단, 실제 투자를 위해서, 월말하루전영업일 기준 자료를 가져옴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# kdata['stage']=''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mkdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;31m#말일자 아님\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m    \u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'before_last'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3948\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3949\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3950\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3952\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4142\u001b[0m         \"\"\"\n\u001b[1;32m-> 4143\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4145\u001b[0m         if (\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4870\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4871\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m    575\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (585) does not match length of index (150)"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "# -1. MDD 함수 정의\n",
    "def MDD(list_values): \n",
    " mdd_value = 0 \n",
    " for i in range(1, len(list_values)): \n",
    "    bw_max = max(list_values[:i]) \n",
    "    curr = list_values[i] \n",
    "    mdd = curr / bw_max - 1 \n",
    " if mdd < mdd_value: \n",
    "    mdd_value = mdd \n",
    " return mdd_value \n",
    "# 0. 사후방향성 클래스를 수치로 전환하는 함수 정의 (up=1, neutral=0, down=-1) \n",
    "def convert_num(pred): \n",
    "    pred_num = np.empty(len(pred)) \n",
    "    pred_num[pred=='up']=1 \n",
    "    pred_num[pred=='neutral']=0 \n",
    "    pred_num[pred=='down']=-1 \n",
    "    pred_num[pred.isna()]=np.NaN \n",
    "    \n",
    "    return pred_num \n",
    "# 1. 월간 시장수익률 데이터 가져오기\n",
    "# 데이터는 일자/월수익률(원수치)/코스피지수/월말하루전영업일로 구성\n",
    "kdata = pd.read_csv(\"kospi_month_end.csv\")\n",
    "# 2. AI모델로 예측한 예측정보를 가져오기\n",
    "# 기존 AI모델 학습 프로세스에서 만들어낸 y_pred 데이터를 조회함. \n",
    "# 매월말에 예측했던 투자의견을 가져옴. 단, 실제 투자를 위해서, 월말하루전영업일 기준 자료를 가져옴\n",
    "# kdata['stage']='' \n",
    "kdata['stage'] = y_pred #말일자 아님\n",
    "for index in kdata.index: \n",
    "   kdata.loc[index,'stage']=y_pred[kdata.loc[index,'before_last']] \n",
    "# 3. 전월말 투자의견 열 생성\n",
    "kdata['pre_stage']= kdata['stage'].shift(1) \n",
    "kdata['port_return']=0 \n",
    "# 4. 전략 수익률 생성\n",
    "# 전월말 투자의견이 상승이면 코스피 long, 보합이면 Cash, 하락이면 코스피 Short 실행. \n",
    "# 해당 전략에 따라 포트 월별수익률(port_return) 생성\n",
    "kdata.loc[kdata['pre_stage']=='up', 'port_return'] = kdata['m_return']*1 \n",
    "kdata.loc[kdata['pre_stage'].isna(), 'port_return'] = kdata['m_return']*1 \n",
    "kdata.loc[kdata['pre_stage']=='neutral', 'port_return'] = 0 \n",
    "kdata.loc[kdata['pre_stage']=='down', 'port_return'] = kdata['m_return']*-1 \n",
    "# 코스피와 모델포트폴리오의 누적수익률(1에서 시작하는 인덱스 형태) 생성\n",
    "kdata['kospi_cumul']=(1+kdata['m_return']).cumprod() \n",
    "kdata['port_cumul']=(1+kdata['port_return']).cumprod() \n",
    "# 5. 백테스팅 결과 기록(CAGR, 변동성, Sharpe ratio, MDD) \n",
    "my_back = {'months':len(kdata)} \n",
    "\n",
    "my_back['k_cumul_return_idx']=kdata['kospi_cumul'][-1] \n",
    "my_back['k_cumul_return_pct']=(my_back['k_cumul_return_idx']-1)*100 \n",
    "my_back['k_cagr']=(my_back['k_cumul_return_idx']**(12/my_back['months']))-1 \n",
    "my_back['k_cagr_pct']=my_back['k_cagr']*100 \n",
    "my_back['k_vol_pct']=np.std(kdata['m_return'])*np.sqrt(12)*100 \n",
    "my_back['k_Sharpe']=my_back['k_cagr_pct']/my_back['k_vol_pct'] \n",
    "my_back['k_MDD']=MDD(kdata['kospi_cumul'])*100 \n",
    "\n",
    "my_back['port_cumul_return_idx']=kdata['port_cumul'][-1] \n",
    "my_back['port_cumul_return_pct']=(my_back['port_cumul_return_idx']-1)*100 \n",
    "my_back['port_cagr']=(my_back['port_cumul_return_idx']**(12/my_back['months']))-1 \n",
    "my_back['port_cagr_pct']=my_back['port_cagr']*100 \n",
    "my_back['port_vol_pct']=np.std(kdata['port_return'])*np.sqrt(12)*100 \n",
    "my_back['port__Sharpe']=my_back['port_cagr_pct']/my_back['port_vol_pct'] \n",
    "my_back['port_MDD']=MDD(kdata['port_cumul'])*100 \n",
    "\n",
    "# 6. 백테스팅 결과 출력하기\n",
    "print(\"<Backtesting result>\") \n",
    "for key, value in my_back.items(): \n",
    " print(\"{:22}: {:>8.3f}\".format(key, value)) \n",
    " \n",
    "# 포트폴리오 누적수익률 그래프\n",
    "kdata['port_cumul'].plot() \n",
    "plt.title('Portfolio performance index') \n",
    "plt.ylabel('\\'02/12/31 = 1') \n",
    "plt.show() \n",
    "\n",
    "# 7. 월말 모델전망치와 실제결과치 출력\n",
    "# 월말 실제결과치 입력\n",
    "for index in kdata.index: \n",
    "\n",
    " kdata.loc[index,'real_stage']=y[kdata.loc[index,'before_last']] \n",
    "# 사후방향성 클래스를 수치로 변환\n",
    "kdata['stage_num']=convert_num(kdata['stage']) \n",
    "kdata['real_stage_num']=convert_num(kdata['real_stage']) \n",
    "\n",
    "# 전망치와 결과치의 그래프 출력\n",
    "kdata.plot(y=['stage_num', 'real_stage_num'], label=['model forecast','real direction']) \n",
    "plt.title('Model forecast vs. Real direction') \n",
    "plt.ylabel('up=1, neutral=0, down=-1') \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
