{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# 티커와 그에 해당하는 이름을 정의합니다.\n",
    "# 사용자는 이 딕셔너리에 새로운 티커와 이름을 추가할 수 있습니다.\n",
    "tickers = {\n",
    "    \"CL=F\": \"WTI\",\n",
    "    \"USDKRW=X\": \"USDKRW\",\n",
    "    \"^KS11\": \"KOSPI200\",\n",
    "    \"^VIX\": \"VIX\"\n",
    "}\n",
    "\n",
    "data = pd.DataFrame()  # 빈 DataFrame을 초기화합니다.\n",
    "\n",
    "# 각 티커에 대한 데이터를 다운로드하고 단일 DataFrame으로 병합합니다.\n",
    "for ticker, name in tickers.items():\n",
    "    series = yf.download(ticker, start=\"2006-12-30\", end=\"2023-09-21\")['Close']  # 각 티커에 대한 종가 데이터를 다운로드합니다.\n",
    "    series.name = name  # 다운로드한 시리즈의 이름을 설정합니다.\n",
    "    if data.empty:  # 첫 번째 티커의 경우, data DataFrame을 초기화합니다.\n",
    "        data = pd.DataFrame(series).reset_index()\n",
    "    else:  # 그 이후의 티커에 대해서는 data DataFrame과 병합합니다.\n",
    "        data = pd.merge(data, pd.DataFrame(series).reset_index(), on='Date', how='outer')\n",
    "\n",
    "# 'Date' 컬럼의 이름을 변경하고 인덱스로 설정합니다.\n",
    "data.rename(columns={'Date': 'Date'}, inplace=True)\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# 누락된 데이터를 처리합니다.\n",
    "data.fillna(method='ffill', inplace=True)  # 누락된 데이터를 앞쪽으로 채웁니다.\n",
    "data.fillna(method='bfill', inplace=True)  # 시작 부분의 누락된 데이터를 뒤쪽으로 채웁니다.\n",
    "\n",
    "# KOSPI 200에 대한 포워드 스테이지를 계산합니다.\n",
    "forward_days = 60\n",
    "data['Forward_Return'] = data['KOSPI200'].shift(-forward_days) / data['KOSPI200'] - 1  # 포워드 리턴을 계산합니다.\n",
    "data['forward_stage'] = pd.cut(data['Forward_Return'], bins=[-float('inf'), 0, 0.04, float('inf')], labels=['down', 'neutral', 'up'])  # 포워드 리턴을 기반으로 스테이지를 분류합니다.\n",
    "\n",
    "# 'forward_stage'에서 NaN이 있는 행을 삭제합니다.\n",
    "data.dropna(subset=['forward_stage'], inplace=True)\n",
    "\n",
    "# 숫자형 컬럼을 2소수점 자리로 반올림합니다.\n",
    "numerical_columns = [name for name in tickers.values() if name != 'KOSPI200']  # 'KOSPI200'을 제외한 모든 컬럼을 선택합니다.\n",
    "data[numerical_columns] = data[numerical_columns].round(2)  # 선택한 컬럼을 반올림합니다.\n",
    "\n",
    "# 인덱스를 재설정하고 'Date' 컬럼을 형식화합니다.\n",
    "data.reset_index(inplace=True)\n",
    "data['Date'] = data['Date'].dt.strftime('%y-%m-%d')\n",
    "\n",
    "# 'Forward_Return' 컬럼을 삭제하고 컬럼 순서를 재배열합니다.\n",
    "data = data[['Date', 'forward_stage'] + numerical_columns]\n",
    "\n",
    "# 필요한 경우 CSV로 저장합니다.\n",
    "data.to_csv('daily_data_value.csv', index=False)\n",
    "\n",
    "# DataFrame의 처음 몇 행을 출력합니다.\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 50, 'max_features': 3, 'max_depth': 15}\n",
      "\n",
      "<10-fold cross-validation>\n",
      "accuracy score mean:  0.8838698795180722\n",
      "\n",
      "<AI model: machine learning done >\n",
      "accuracy_score of train data(0.8 of sample):  1.0\n",
      "accuracy_score of test data(0.2 of sample):  0.896\n",
      "\n",
      "<Confusion matrix>\n",
      "(of test)\n",
      "up neutral down\n",
      "[[165  13   0]\n",
      " [ 13 112  29]\n",
      " [  2   8 283]]\n",
      "(of all)\n",
      "up neutral down\n",
      "[[ 877   13    0]\n",
      " [  13  726   29]\n",
      " [   2    8 1454]]\n",
      "\n",
      "<Feature importance>\n",
      "WTI :  0.12212993396205372\n",
      "USDKRW :  0.08642475968926346\n",
      "VIX :  0.10624318204393458\n",
      "1 :  0.03702338144595293\n",
      "2 :  0.06734255759075593\n",
      "3 :  0.04858756800163593\n",
      "4 :  0.04879658938104437\n",
      "5 :  0.06990049290174645\n",
      "6 :  0.050243237625976295\n",
      "7 :  0.038876174408364536\n",
      "8 :  0.040438762555648454\n",
      "9 :  0.027605998496899643\n",
      "10 :  0.036301257976774394\n",
      "per :  0.11931051387050046\n",
      "pbr :  0.10077559004944885\n",
      "\n",
      "< AI model: save >\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.metrics as mt \n",
    "from sklearn.tree import export_graphviz \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "import joblib \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# 1. Load the modified CSV data\n",
    "model_data = pd.read_csv(\"correct_datasets.csv\", encoding='cp949')\n",
    "\n",
    "# Set 'Date' column as index\n",
    "model_data.set_index('Date', inplace=True)\n",
    "\n",
    "# 2. Generate complete data of features and label\n",
    "X = model_data.drop(columns=['forward_stage'])  # Exclude the 'forward_stage' column for features\n",
    "y = model_data['forward_stage']  # Use 'forward_stage' column as label\n",
    "\n",
    "X_past = X[y.notna()] \n",
    "y_past = y[y.notna()]\n",
    "\n",
    "# 3. Split the data into train and test\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(X_past, y_past):\n",
    "    X_train, X_test = X_past.iloc[train_index,], X_past.iloc[test_index,] \n",
    "    y_train, y_test = y_past.iloc[train_index], y_past.iloc[test_index]\n",
    "\n",
    "# 4. Model fine-tuning: find optimal hyperparameters\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=42)  # n_jobs를 1로 설정\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100], # 500 제외\n",
    "    'max_leaf_nodes': [20, 30, 40, 50], # 40, 50 제외\n",
    "    'max_features': [1, 2, 3],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(rnd_clf, param_dist_rf, cv=10, random_state=42)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "print(rnd_search.best_params_)\n",
    "\n",
    "# 5. Train the model and evaluate it using K-fold cross-validation\n",
    "rnd_search = RandomizedSearchCV(rnd_clf, param_dist_rf, cv=10, random_state=42, n_jobs=-1)  # n_jobs를 1로 설정\n",
    "rnd_scores = cross_val_score(rnd_clf, X_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "print(\"\\n<10-fold cross-validation>\")\n",
    "print(\"accuracy score mean: \", rnd_scores.mean())\n",
    "\n",
    "# 6. Train the final model\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(\"\\n<AI model: machine learning done >\")\n",
    "print(\"accuracy_score of train data(0.8 of sample): \", rnd_clf.score(X_train, y_train))\n",
    "\n",
    "# 7. Evaluate the model on test data\n",
    "print(\"accuracy_score of test data(0.2 of sample): \", rnd_clf.score(X_test, y_test))\n",
    "\n",
    "# 8. Check the confusion matrix\n",
    "y_test_pred = rnd_clf.predict(X_test) \n",
    "cm1 = confusion_matrix(y_test, y_test_pred, labels=[\"up\", \"neutral\", \"down\"]) \n",
    "print(\"\\n<Confusion matrix>\")\n",
    "print(\"(of test)\")\n",
    "print(\"up\", \"neutral\", \"down\")\n",
    "print(cm1)\n",
    "cm2 = confusion_matrix(y_past, rnd_clf.predict(X_past), labels=[\"up\", \"neutral\", \"down\"]) \n",
    "print(\"(of all)\")\n",
    "print(\"up\", \"neutral\", \"down\")\n",
    "print(cm2)\n",
    "\n",
    "# 9. Check feature importance\n",
    "print(\"\\n<Feature importance>\")\n",
    "for name, score in zip(X.columns, rnd_clf.feature_importances_):\n",
    "    print(name, \": \", score)\n",
    "\n",
    "# 10. Generate prediction data for backtesting\n",
    "y_prediction = rnd_clf.predict(X)\n",
    "y_pred = pd.Series(y_prediction, index=y.index)\n",
    "\n",
    "# 11. Save the model\n",
    "joblib.dump(rnd_clf, \"forecast_model.pkl\")\n",
    "print(\"\\n< AI model: save >\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml2.py code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. 모델 로드\n",
    "rnd_clf = joblib.load(\"forecast_model.pkl\")\n",
    "print(\"\\n< AI model: load >\")\n",
    "\n",
    "# 2. new daily raw data 가져오기\n",
    "model_data = pd.read_csv(\"3.csv\")\n",
    "\n",
    "# 'forward_stage' 컬럼을 숫자로 변환합니다.\n",
    "categories = model_data['forward_stage'].astype('category')\n",
    "model_data['forward_stage'] = categories.cat.codes\n",
    "\n",
    "# X는 'forward_stage'와 'Date'를 제외한 모든 컬럼을 포함해야 합니다.\n",
    "X = model_data.drop(columns=['forward_stage', 'Date'])\n",
    "X.columns = X.columns.astype(str)  # Set feature names to avoid warning\n",
    "y = model_data[\"forward_stage\"]\n",
    "\n",
    "# y가 NaN이 아닌 행만 선택합니다.\n",
    "X_past = X[y.notna()]\n",
    "y_past = y[y.notna()]\n",
    "\n",
    "# 3. new daily raw data 전체 학습\n",
    "rnd_clf.fit(X_past, y_past)\n",
    "print(\"\\n< AI model: machine learning done >\")\n",
    "print(\"accuracy_score of whole data: \", rnd_clf.score(X_past, y_past))\n",
    "\n",
    "# 4. 현재(마지막) 데이터 표시\n",
    "print(\"\\n<Current status>\")\n",
    "for col, score in zip(X.columns, X.iloc[-1]):\n",
    "    print(\"{:20} : {:>8.3f}\".format(col, score))\n",
    "\n",
    "X_current = np.array(X.iloc[-1]).reshape(1, -1)\n",
    "\n",
    "# 5. 현재 전망\n",
    "print(\"\\n< AI model: forecasting >\")\n",
    "y_current_pred = rnd_clf.predict(X_current)\n",
    "print(\"forecast: \", categories.cat.categories[y_current_pred[0]])\n",
    "\n",
    "# 현재전망의 확률표\n",
    "prob_current = rnd_clf.predict_proba(X_current)\n",
    "y_names = rnd_clf.classes_\n",
    "print(\"\\n[class] : [prob]\")\n",
    "for name, prob in zip(categories.cat.categories[y_names], prob_current[0]):\n",
    "    print(\"{:7} : {:.2f}\".format(name, prob))\n",
    "\n",
    "# # 6. 2023년 일별 전망치의 확률 변화\n",
    "# # 전기간 전망치 확률 데이터생성\n",
    "# prob = rnd_clf.predict_proba(X)\n",
    "# prob_df = pd.DataFrame(prob, columns=categories.cat.categories)\n",
    "\n",
    "# # '2023'이라는 컬럼이나 인덱스는 없으므로, 'Date' 컬럼에서 '2023'년에 해당하는 데이터를 선택해야 합니다.\n",
    "# model_data['Year'] = pd.to_datetime(model_data['Date'], format='%y-%m-%d').dt.year\n",
    "# prob_2023 = prob_df[model_data['Year'] == 2023]\n",
    "\n",
    "# # '2023'년에 해당하는 날짜를 가져옵니다.\n",
    "# dates_2023 = model_data.loc[model_data['Year'] == 2023, 'Date']\n",
    "\n",
    "# plt.bar(dates_2023, prob_2023['up'], label='up', color='r')\n",
    "# plt.bar(dates_2023, prob_2023['neutral'], label='neutral', color='g', bottom=prob_2023['up'])\n",
    "# plt.bar(dates_2023, prob_2023['down'], label='down', color='b', bottom=prob_2023[['up', 'neutral']].sum(axis=1))\n",
    "# plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "# -1. MDD 함수 정의\n",
    "def MDD(list_values): \n",
    " mdd_value = 0 \n",
    " for i in range(1, len(list_values)): \n",
    "    bw_max = max(list_values[:i]) \n",
    "    curr = list_values[i] \n",
    "    mdd = curr / bw_max - 1 \n",
    " if mdd < mdd_value: \n",
    "    mdd_value = mdd \n",
    " return mdd_value \n",
    "# 0. 사후방향성 클래스를 수치로 전환하는 함수 정의 (up=1, neutral=0, down=-1) \n",
    "def convert_num(pred): \n",
    "    pred_num = np.empty(len(pred)) \n",
    "    pred_num[pred=='up']=1 \n",
    "    pred_num[pred=='neutral']=0 \n",
    "    pred_num[pred=='down']=-1 \n",
    "    pred_num[pred.isna()]=np.NaN \n",
    "    \n",
    "    return pred_num \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2007-04-29'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3653\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2007-04-29'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8364\\1014580719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;31m#말일자 아님\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m  \u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'before_last'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# 3. 전월말 투자의견 열 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mkdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre_stage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mkdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m             \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2007-04-29'"
     ]
    }
   ],
   "source": [
    "# backtest.py code\n",
    "# 1. 월간 시장수익률 데이터 가져오기\n",
    "# 데이터는 일자/월수익률(원수치)/코스피지수/월말하루전영업일로 구성\n",
    "kdata = pd.read_csv(\"investing.csv\")\n",
    "# 2. AI모델로 예측한 예측정보를 가져오기\n",
    "# 기존 AI모델 학습 프로세스에서 만들어낸 y_pred 데이터를 조회함. \n",
    "# 매월말에 예측했던 투자의견을 가져옴. 단, 실제 투자를 위해서, 월말하루전영업일 기준 자료를 가져옴\n",
    "# kdata['stage']='' \n",
    "kdata['stage'] = y_pred #말일자 아님\n",
    "for index in kdata.index: \n",
    " kdata.loc[index,'stage']=y_pred[kdata.loc[index,'before_last']] \n",
    "# 3. 전월말 투자의견 열 생성\n",
    "kdata['pre_stage']= kdata['stage'].shift(1) \n",
    "kdata['port_return']=0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 전략 수익률 생성\n",
    "# 전월말 투자의견이 상승이면 코스피 long, 보합이면 Cash, 하락이면 코스피 Short 실행. \n",
    "# 해당 전략에 따라 포트 월별수익률(port_return) 생성\n",
    "kdata.loc[kdata['pre_stage']=='up', 'port_return'] = kdata['m_return']*1 \n",
    "kdata.loc[kdata['pre_stage'].isna(), 'port_return'] = kdata['m_return']*1 \n",
    "kdata.loc[kdata['pre_stage']=='neutral', 'port_return'] = 0 \n",
    "kdata.loc[kdata['pre_stage']=='down', 'port_return'] = kdata['m_return']*-1 \n",
    "# 코스피와 모델포트폴리오의 누적수익률(1에서 시작하는 인덱스 형태) 생성\n",
    "kdata['kospi_cumul']=(1+kdata['m_return']).cumprod() \n",
    "kdata['port_cumul']=(1+kdata['port_return']).cumprod() \n",
    "# 5. 백테스팅 결과 기록(CAGR, 변동성, Sharpe ratio, MDD) \n",
    "my_back = {'months':len(kdata)} \n",
    "\n",
    "my_back['k_cumul_return_idx']=kdata['kospi_cumul'][-1] \n",
    "my_back['k_cumul_return_pct']=(my_back['k_cumul_return_idx']-1)*100 \n",
    "my_back['k_cagr']=(my_back['k_cumul_return_idx']**(12/my_back['months']))-1 \n",
    "my_back['k_cagr_pct']=my_back['k_cagr']*100 \n",
    "my_back['k_vol_pct']=np.std(kdata['m_return'])*np.sqrt(12)*100 \n",
    "my_back['k_Sharpe']=my_back['k_cagr_pct']/my_back['k_vol_pct'] \n",
    "my_back['k_MDD']=MDD(kdata['kospi_cumul'])*100 \n",
    "\n",
    "my_back['port_cumul_return_idx']=kdata['port_cumul'][-1] \n",
    "my_back['port_cumul_return_pct']=(my_back['port_cumul_return_idx']-1)*100 \n",
    "my_back['port_cagr']=(my_back['port_cumul_return_idx']**(12/my_back['months']))-1 \n",
    "my_back['port_cagr_pct']=my_back['port_cagr']*100 \n",
    "my_back['port_vol_pct']=np.std(kdata['port_return'])*np.sqrt(12)*100 \n",
    "my_back['port__Sharpe']=my_back['port_cagr_pct']/my_back['port_vol_pct'] \n",
    "my_back['port_MDD']=MDD(kdata['port_cumul'])*100 \n",
    "\n",
    "# 6. 백테스팅 결과 출력하기\n",
    "print(\"<Backtesting result>\") \n",
    "for key, value in my_back.items(): \n",
    " print(\"{:22}: {:>8.3f}\".format(key, value)) \n",
    " \n",
    "# 포트폴리오 누적수익률 그래프\n",
    "kdata['port_cumul'].plot() \n",
    "plt.title('Portfolio performance index') \n",
    "plt.ylabel('\\'02/12/31 = 1') \n",
    "plt.show() \n",
    "\n",
    "# 7. 월말 모델전망치와 실제결과치 출력\n",
    "# 월말 실제결과치 입력\n",
    "for index in kdata.index: \n",
    "\n",
    " kdata.loc[index,'real_stage']=y[kdata.loc[index,'before_last']] \n",
    "# 사후방향성 클래스를 수치로 변환\n",
    "kdata['stage_num']=convert_num(kdata['stage']) \n",
    "kdata['real_stage_num']=convert_num(kdata['real_stage']) \n",
    "\n",
    "# 전망치와 결과치의 그래프 출력\n",
    "kdata.plot(y=['stage_num', 'real_stage_num'], label=['model forecast','real direction']) \n",
    "plt.title('Model forecast vs. Real direction') \n",
    "plt.ylabel('up=1, neutral=0, down=-1') \n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
