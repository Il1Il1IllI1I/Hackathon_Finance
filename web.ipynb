{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import chromedriver_autoinstaller\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By\n",
    "import random\n",
    "\n",
    "sleep_time = random.uniform(1, 2)\n",
    "\n",
    "\n",
    "# 크롬 디버거로 크롬 구동\n",
    "subprocess.Popen(r'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe --remote-debugging-port=9222 --user-data-dir=\"C:\\chrometemp\"')\n",
    "time.sleep(3)  # 크롬이 완전히 실행될 때까지 대기\n",
    "\n",
    "# 웹드라이버 설정\n",
    "chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]\n",
    "driver_path = f'./{chrome_ver}/chromedriver.exe'\n",
    "option = Options()\n",
    "option.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "\n",
    "try:\n",
    "    driver = webdriver.Chrome(driver_path, options=option)\n",
    "except:\n",
    "    chromedriver_autoinstaller.install(True)\n",
    "    driver = webdriver.Chrome(driver_path, options=option)\n",
    "\n",
    "driver.implicitly_wait(5)  # 웹 자원 로드를 위해 5초까지 기다림\n",
    "\n",
    "input(\"홈페이지 접속하면 ENTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calender = driver.find_element(By.XPATH, '//*[@id=\"MDCSTAT007_FORM\"]/div[2]/div/table/tbody/tr[3]/td/div/div/button')\n",
    "\n",
    "# calender.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_numeric_values(driver):\n",
    "#     calender = driver.find_element(By.XPATH, '//*[@id=\"MDCSTAT007_FORM\"]/div[2]/div/table/tbody/tr[3]/td/div/div/button')\n",
    "#     calender.click()\n",
    "#     # a 태그 중에서 href 속성 값이 '#' 인 것들을 모두 찾기\n",
    "#     elements = driver.find_elements(By.CSS_SELECTOR, \"a[href='#']\")\n",
    "    \n",
    "#     # 숫자인 텍스트 값을 저장할 리스트\n",
    "#     numeric_values = []\n",
    "    \n",
    "#     for elem in elements:\n",
    "#         text = elem.text  # 링크의 텍스트 값을 얻기\n",
    "#         if text.isdigit():  # 텍스트 값이 숫자인지 확인\n",
    "#             numeric_values.append(text)  # 숫자인 경우 리스트에 추가\n",
    "    \n",
    "#     return numeric_values  # 리스트 반환\n",
    "\n",
    "\n",
    "# # 함수를 호출하여 숫자인 텍스트 값을 얻기\n",
    "# numeric_values = get_numeric_values(driver)\n",
    "\n",
    "# # 반환된 리스트를 출력\n",
    "# print(numeric_values)  # 예: ['1', '4', '5', '6', '7', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # CSV 파일에서 데이터를 로드합니다.\n",
    "# file_path = 'feature.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # date 칼럼이 있는지 확인합니다.\n",
    "# if 'Date' in data.columns:\n",
    "#     # date 칼럼의 값들을 리스트로 변환합니다.\n",
    "# # Date 칼럼의 값들을 리스트로 변환합니다.\n",
    "#     date_list = data['Date'].tolist()\n",
    "\n",
    "# # 날짜를 원하는 형식으로 변환합니다.\n",
    "# formatted_date_list = []\n",
    "# for date_str in date_list:\n",
    "#     try:\n",
    "#         # 날짜를 datetime 객체로 변환\n",
    "#         date_obj = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "#         # datetime 객체를 원하는 문자열 형식으로 변환\n",
    "#         formatted_date_str = date_obj.strftime('%Y%m%d')\n",
    "#         formatted_date_list.append(formatted_date_str)\n",
    "#     except ValueError as e:  # 날짜 변환 오류 처리\n",
    "#         print(f\"Error converting date {date_str}: {e}\")\n",
    "#         formatted_date_list.append(None)\n",
    "\n",
    "# # 변환된 formatted_date_list의 처음 5개 값을 반환합니다.\n",
    "# formatted_date_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20230801', '20230802', '20230803', '20230804', '20230807']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# CSV 파일을 읽어 DataFrame으로 로드합니다.\n",
    "file_path = 'datasets.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'Date' 칼럼을 datetime 타입으로 변환합니다.\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 사용자로부터 시작 날짜와 종료 날짜를 입력받습니다.\n",
    "start_date_input = input(\"시작 날짜를 입력하세요 (YYYY-MM-DD): \")\n",
    "end_date_input = input(\"종료 날짜를 입력하세요 (YYYY-MM-DD): \")\n",
    "\n",
    "# 입력받은 날짜 문자열을 datetime 객체로 변환합니다.\n",
    "start_date = datetime.strptime(start_date_input, '%Y-%m-%d')\n",
    "end_date = datetime.strptime(end_date_input, '%Y-%m-%d')\n",
    "\n",
    "# 지정된 날짜 범위로 데이터를 필터링합니다.\n",
    "filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "# 필터링된 DataFrame에서 'Date' 칼럼만 추출하여 리스트로 변환합니다.\n",
    "formatted_date_list = filtered_df['Date'].dt.strftime('%Y%m%d').tolist()\n",
    "\n",
    "# 결과 확인을 위해 상위 5개 날짜를 출력합니다.\n",
    "print(formatted_date_list[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230801 - Data has been successfully saved to interim_result.csv\n",
      "20230802 - Data has been successfully saved to interim_result.csv\n",
      "20230803 - Data has been successfully saved to interim_result.csv\n",
      "20230804 - Data has been successfully saved to interim_result.csv\n",
      "20230807 - Data has been successfully saved to interim_result.csv\n",
      "20230808 - Data has been successfully saved to interim_result.csv\n",
      "20230809 - Data has been successfully saved to interim_result.csv\n",
      "20230810 - Data has been successfully saved to interim_result.csv\n",
      "20230811 - Data has been successfully saved to interim_result.csv\n",
      "20230814 - Data has been successfully saved to interim_result.csv\n",
      "20230815 - Data has been successfully saved to interim_result.csv\n",
      "20230816 - Data has been successfully saved to interim_result.csv\n",
      "20230817 - Data has been successfully saved to interim_result.csv\n",
      "20230818 - Data has been successfully saved to interim_result.csv\n",
      "20230821 - Data has been successfully saved to interim_result.csv\n",
      "20230822 - Data has been successfully saved to interim_result.csv\n",
      "20230823 - Data has been successfully saved to interim_result.csv\n",
      "20230824 - Data has been successfully saved to interim_result.csv\n",
      "20230825 - Data has been successfully saved to interim_result.csv\n",
      "20230828 - Data has been successfully saved to interim_result.csv\n",
      "20230829 - Data has been successfully saved to interim_result.csv\n",
      "20230830 - Data has been successfully saved to interim_result.csv\n",
      "20230831 - Data has been successfully saved to interim_result.csv\n",
      "        Date  1_PER  1_PBR  2_PER  2_PBR  3_PER  3_PBR  4_PER  4_PBR  5_PER  \\\n",
      "0   20230801  14.32   0.96  10.07   0.88    NaN   1.57   8.11   0.57  13.03   \n",
      "1   20230802  14.03   0.94   9.88   0.86    NaN   1.55   7.90   0.56  12.74   \n",
      "2   20230803  13.94   0.93   9.81   0.85    NaN   1.51   7.96   0.56  13.02   \n",
      "3   20230804  13.94   0.93   9.73   0.85    NaN   1.52   7.89   0.56  12.97   \n",
      "4   20230807  13.87   0.93   9.45   0.82    NaN   1.51   7.68   0.54  12.67   \n",
      "5   20230808  13.80   0.92   9.48   0.83    NaN   1.53   7.88   0.56  12.58   \n",
      "6   20230809  13.95   0.93   9.55   0.83    NaN   1.53   7.86   0.56  12.63   \n",
      "7   20230810  13.90   0.93   9.61   0.84    NaN   1.52   7.84   0.55  12.62   \n",
      "8   20230811  13.84   0.92   9.58   0.83    NaN   1.52   7.75   0.55  12.55   \n",
      "9   20230814  13.74   0.92   9.51   0.83    NaN   1.48   7.67   0.54  12.22   \n",
      "10  20230815    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "11  20230816  13.53   0.90   9.21   0.80    NaN   1.44   7.42   0.52  11.80   \n",
      "12  20230817  13.49   0.90   9.28   0.81    NaN   1.43   7.45   0.53  11.82   \n",
      "13  20230818  13.41   0.90   9.16   0.80    NaN   1.41   7.38   0.52  11.61   \n",
      "14  20230821  13.43   0.90   9.14   0.80    NaN   1.41   7.45   0.53  11.73   \n",
      "15  20230822  13.47   0.90   9.24   0.81    NaN   1.41   7.45   0.53  11.73   \n",
      "16  20230823  13.44   0.90   9.20   0.80    NaN   1.42   7.40   0.52  11.54   \n",
      "17  20230824  13.63   0.91   9.48   0.83    NaN   1.42   7.57   0.53  11.56   \n",
      "18  20230825  13.49   0.90   9.24   0.80    NaN   1.41   7.62   0.54  11.53   \n",
      "19  20230828  13.58   0.91   9.60   0.84    NaN   1.48   7.82   0.55  11.78   \n",
      "20  20230829  13.63   0.91   9.56   0.83    NaN   1.51   7.79   0.55  11.78   \n",
      "21  20230830  13.68   0.91   9.56   0.83    NaN   1.50   7.88   0.56  11.88   \n",
      "22  20230831  13.67   0.91   9.38   0.82    NaN   1.51   7.85   0.55  11.85   \n",
      "\n",
      "    5_PBR  6_PER  6_PBR  7_PER  7_PBR  8_PER  8_PBR  9_PER  9_PBR  \n",
      "0    0.82  58.96   1.16   4.96   0.43    NaN   0.67   7.79   0.68  \n",
      "1    0.80  57.51   1.14   4.90   0.42    NaN   0.67   7.56   0.66  \n",
      "2    0.82  56.87   1.12   4.84   0.42    NaN   0.67   7.56   0.66  \n",
      "3    0.82  56.62   1.12   4.91   0.42    NaN   0.68   7.61   0.66  \n",
      "4    0.80  56.78   1.12   4.92   0.43    NaN   0.69   7.49   0.65  \n",
      "5    0.79  55.97   1.10   4.94   0.43    NaN   0.68   7.49   0.65  \n",
      "6    0.79  56.69   1.12   4.88   0.42    NaN   0.68   7.55   0.66  \n",
      "7    0.79  56.19   1.11   4.86   0.42    NaN   0.71   7.67   0.67  \n",
      "8    0.79  56.00   1.11   4.88   0.42    NaN   0.71   7.76   0.68  \n",
      "9    0.77  55.24   1.09   4.87   0.42    NaN   0.72   7.76   0.68  \n",
      "10    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "11   0.74  54.82   1.08   4.80   0.41    NaN   0.70   7.62   0.67  \n",
      "12   0.74  54.71   1.08   4.80   0.41    NaN   0.69   7.60   0.66  \n",
      "13   0.73  54.63   1.08   4.80   0.41    NaN   0.69   7.58   0.66  \n",
      "14   0.74  54.52   1.08   4.82   0.42    NaN   0.69   7.55   0.66  \n",
      "15   0.74  54.65   1.08   4.82   0.42    NaN   0.69   7.59   0.66  \n",
      "16   0.73  54.50   1.08   4.86   0.42    NaN   0.69   7.56   0.66  \n",
      "17   0.73  55.73   1.10   4.85   0.42    NaN   0.69   7.54   0.66  \n",
      "18   0.73  54.75   1.08   4.85   0.42    NaN   0.70   7.54   0.66  \n",
      "19   0.74  54.87   1.08   4.88   0.42    NaN   0.70   7.59   0.66  \n",
      "20   0.74  55.10   1.09   4.91   0.42    NaN   0.70   7.66   0.67  \n",
      "21   0.75  55.47   1.09   4.91   0.42    NaN   0.70   7.69   0.67  \n",
      "22   0.75  55.67   1.10   4.97   0.43    NaN   0.70   7.69   0.67  \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np  # NaN 처리를 위해 import\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "\n",
    "# 결과를 저장할 DataFrame 생성. 초기에는 'Date' 칼럼만 있는 상태입니다.\n",
    "result_df = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "# 찾고자 하는 문자열 리스트\n",
    "target_strings = [\n",
    "    '코스피 200', '코스피 200 건설', '코스피 200 중공업', '코스피 200 철강/소재',\n",
    "    '코스피 200 에너지/화학', '코스피 200 정보기술',\n",
    "    '코스피 200 금융', '코스피 200 생활소비재', '코스피 200 경기소비재'\n",
    "]\n",
    "\n",
    "# 각 문자열에 대해 칼럼을 추가합니다.\n",
    "for idx, _ in enumerate(target_strings, start=1):\n",
    "    result_df[f\"{idx}_PER\"] = None\n",
    "    result_df[f\"{idx}_PBR\"] = None\n",
    "\n",
    "# 오류 로그를 저장할 리스트\n",
    "error_log = []\n",
    "\n",
    "def click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath):\n",
    "    for date_str in formatted_date_list:\n",
    "        try:\n",
    "            # 날짜 입력 필드 찾기\n",
    "            date_input = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, input_xpath)))\n",
    "            # 날짜 입력 필드에 값 입력\n",
    "            date_input.clear()\n",
    "            date_input.send_keys(date_str)\n",
    "            \n",
    "            # 검색 버튼 클릭\n",
    "            search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "            search_button.click()\n",
    "            time.sleep(5)  # 페이지 로딩을 위해 잠시 대기\n",
    "            \n",
    "            # 데이터 추출 및 저장\n",
    "            extract_and_save_data(driver, date_str)\n",
    "            \n",
    "            # CSV 파일로 저장하고 상태를 출력합니다.\n",
    "            result_df.to_csv('2014_result.csv', index=False)\n",
    "            print(f\"{date_str} - Data has been successfully saved to interim_result.csv\")\n",
    "            \n",
    "        except Exception as e:  # 모든 예외를 포착합니다.\n",
    "            print(f\"Error with date {date_str}: {e}\")\n",
    "            error_log.append(f\"Error with date {date_str}: {e}\")\n",
    "            \n",
    "            # CSV 파일로 저장하고 상태를 출력합니다.\n",
    "            result_df.to_csv('interim_result.csv', index=False)\n",
    "            print(f\"{date_str} - Data has been successfully saved to interim_result.csv despite the error\")\n",
    "\n",
    "def extract_and_save_data(driver, date_str):\n",
    "    # 현재 페이지의 소스를 가져옵니다.\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup 객체를 생성합니다.\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # 결과를 임시로 저장할 딕셔너리\n",
    "    result_dict = {\"Date\": date_str}\n",
    "    \n",
    "    # 각 문자열에 대해 처리합니다.\n",
    "    for idx, target_string in enumerate(target_strings, start=1):\n",
    "        # 문자열을 포함하는 td 태그를 찾기\n",
    "        target_td = soup.find('td', string=target_string)\n",
    "        \n",
    "        if target_td:\n",
    "            # target_td의 형제들 중에서 data-bind=\"WT_PER\"와 \"WT_STKPRC_NETASST_RTO\" 속성을 가진 태그의 텍스트를 추출\n",
    "            per_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_PER'})\n",
    "            pbr_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_STKPRC_NETASST_RTO'})\n",
    "            \n",
    "            if per_tag and pbr_tag:\n",
    "                try:\n",
    "                    PER = float(per_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PER = np.nan  # NaN으로 설정\n",
    "                \n",
    "                try:\n",
    "                    PBR = float(pbr_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PBR = np.nan  # NaN으로 설정\n",
    "                \n",
    "                # 결과 딕셔너리에 값 추가\n",
    "                result_dict[f\"{idx}_PER\"] = PER\n",
    "                result_dict[f\"{idx}_PBR\"] = PBR\n",
    "            else:\n",
    "                print(f\"{date_str} 날짜, {target_string}에 대한 필요한 태그를 찾지 못했습니다.\")\n",
    "        else:\n",
    "            print(f\"{date_str} 날짜에 {target_string} 문자열을 포함하는 태그를 찾지 못했습니다.\")\n",
    "    \n",
    "    # 결과 DataFrame에 행을 추가합니다.\n",
    "    result_df.loc[len(result_df)] = result_dict\n",
    "\n",
    "# 함수 호출\n",
    "input_xpath = '//input[@id=\"trdDd\"]'\n",
    "search_button_xpath = '//*[@id=\"jsSearchButton\"]'\n",
    "click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath)\n",
    "\n",
    "# 결과 DataFrame 출력\n",
    "print(result_df)\n",
    "\n",
    "# 오류 로그 출력\n",
    "print(error_log)\n",
    "\n",
    "# 최종 결과를 CSV 파일로 저장\n",
    "result_df.to_csv('2014_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np  # NaN 처리를 위해 import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# 오류 로그를 저장할 리스트\n",
    "error_log = []\n",
    "\n",
    "def click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath):\n",
    "    for date_str in formatted_date_list:\n",
    "        try:\n",
    "            # 날짜 입력 필드 찾기\n",
    "            date_input = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, input_xpath)))\n",
    "            # 날짜 입력 필드에 값 입력\n",
    "            date_input.clear()\n",
    "            date_input.send_keys(date_str)\n",
    "            \n",
    "            # 검색 버튼 클릭\n",
    "            search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "            search_button.click()\n",
    "            time.sleep(5)  # 페이지 로딩을 위해 잠시 대기\n",
    "            \n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Error with date {date_str}: {e}\")\n",
    "            error_log.append(f\"Error with date {date_str}: {e}\")\n",
    "            continue  # 다음 날짜로 진행\n",
    "\n",
    "\n",
    "# 함수 호출\n",
    "input_xpath = '//input[@id=\"trdDd\"]'\n",
    "search_button_xpath = '//*[@id=\"jsSearchButton\"]'\n",
    "click_search_button_with_dates(driver, formatted_date_list, input_xpath, search_button_xpath)\n",
    "\n",
    "# 오류 로그 출력\n",
    "print(error_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, 1_PER, 1_PBR, 2_PER, 2_PBR, 3_PER, 3_PBR, 4_PER, 4_PBR, 5_PER, 5_PBR, 6_PER, 6_PBR, 7_PER, 7_PBR, 8_PER, 8_PBR, 9_PER, 9_PBR]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np  # NaN 처리를 위해 import\n",
    "\n",
    "# 결과를 저장할 DataFrame 생성. 초기에는 'Date' 칼럼만 있는 상태입니다.\n",
    "result_df = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "# 찾고자 하는 문자열 리스트\n",
    "target_strings = [\n",
    "    '코스피 200', '코스피 200 건설', '코스피 200 중공업', '코스피 200 철강/소재', \n",
    "    '코스피 200 에너지/화학', '코스피 200 정보기술', \n",
    "    '코스피 200 금융', '코스피 200 생활소비재', '코스피 200 경기소비재'\n",
    "]\n",
    "\n",
    "# 각 문자열에 대해 칼럼을 추가합니다.\n",
    "for idx, _ in enumerate(target_strings, start=1):\n",
    "    result_df[f\"{idx}_PER\"] = None\n",
    "    result_df[f\"{idx}_PBR\"] = None\n",
    "\n",
    "def extract_and_save_data(driver, date_str):\n",
    "    # 현재 페이지의 소스를 가져옵니다.\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup 객체를 생성합니다.\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # 결과를 임시로 저장할 딕셔너리\n",
    "    result_dict = {\"Date\": date_str}\n",
    "    \n",
    "    # 각 문자열에 대해 처리합니다.\n",
    "    for idx, target_string in enumerate(target_strings, start=1):\n",
    "        # 문자열을 포함하는 td 태그를 찾기\n",
    "        target_td = soup.find('td', string=target_string)\n",
    "        \n",
    "        if target_td:\n",
    "            # target_td의 형제들 중에서 data-bind=\"WT_PER\"와 \"WT_STKPRC_NETASST_RTO\" 속성을 가진 태그의 텍스트를 추출\n",
    "            per_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_PER'})\n",
    "            pbr_tag = target_td.find_next_sibling(attrs={'data-bind': 'WT_STKPRC_NETASST_RTO'})\n",
    "            \n",
    "            if per_tag and pbr_tag:\n",
    "                try:\n",
    "                    PER = float(per_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PER = np.nan  # NaN으로 설정\n",
    "                \n",
    "                try:\n",
    "                    PBR = float(pbr_tag.get_text())\n",
    "                except ValueError:  # 숫자로 변환할 수 없는 경우\n",
    "                    PBR = np.nan  # NaN으로 설정\n",
    "                \n",
    "                # 결과 딕셔너리에 값 추가\n",
    "                result_dict[f\"{idx}_PER\"] = PER\n",
    "                result_dict[f\"{idx}_PBR\"] = PBR\n",
    "            else:\n",
    "                print(f\"{date_str} 날짜, {target_string}에 대한 필요한 태그를 찾지 못했습니다.\")\n",
    "        else:\n",
    "            print(f\"{date_str} 날짜에 {target_string} 문자열을 포함하는 태그를 찾지 못했습니다.\")\n",
    "    \n",
    "    # 결과 DataFrame에 행을 추가합니다.\n",
    "    result_df.loc[len(result_df)] = result_dict\n",
    "\n",
    "# 테스트를 위해 formatted_date_list에서 첫 번째 날짜만 선택합니다.\n",
    "test_date_list = formatted_date_list[:1]\n",
    "\n",
    "# 함수 호출\n",
    "click_search_button_with_dates(driver, test_date_list, input_xpath, search_button_xpath)\n",
    "\n",
    "# 결과 DataFrame 출력\n",
    "print(result_df)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "result_df.to_csv('test_result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, 1_PER, 1_PBR, 2_PER, 2_PBR, 3_PER, 3_PBR, 4_PER, 4_PBR, 5_PER, 5_PBR, 6_PER, 6_PBR, 7_PER, 7_PBR, 8_PER, 8_PBR, 9_PER, 9_PBR]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 테스트를 위해 formatted_date_list에서 첫 번째 날짜만 선택합니다.\n",
    "test_date_list = formatted_date_list[:1]\n",
    "\n",
    "# 함수 호출\n",
    "click_search_button_with_dates(driver, test_date_list, input_xpath, search_button_xpath)\n",
    "\n",
    "# 결과 DataFrame 출력\n",
    "print(result_df)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "result_df.to_csv('test_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "def get_numeric_values(driver):\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, \"a[href='#']\")\n",
    "    numeric_values = [elem.text for elem in elements if elem.text.isdigit()]\n",
    "    return numeric_values\n",
    "\n",
    "def click_numeric_values_and_search(driver, numeric_values, calender_xpath, search_button_xpath):\n",
    "    calender = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, calender_xpath)))\n",
    "    \n",
    "    for value in numeric_values:\n",
    "        calender.click()\n",
    "        time.sleep(2)  # 페이지 로딩을 위해 잠시 대기\n",
    "        \n",
    "        try:\n",
    "            # numeric_value 클릭\n",
    "            numeric_element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, f\"//a[text()='{value}' and @href='#']\")))\n",
    "            numeric_element.click()\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # jsSearchButton 클릭\n",
    "            search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, search_button_xpath)))\n",
    "            search_button.click()\n",
    "            time.sleep(5)  # 페이지 로딩을 위해 잠시 대기\n",
    "            \n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "# numeric_values 리스트 얻기\n",
    "numeric_values = get_numeric_values(driver)\n",
    "\n",
    "# numeric_values 리스트의 각 값에 대해 클릭하고 검색 수행\n",
    "click_numeric_values_and_search(driver, numeric_values, '//*[@id=\"MDCSTAT007_FORM\"]/div[2]/div/table/tbody/tr[3]/td/div/div/button', '//*[@id=\"jsSearchButton\"]')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
