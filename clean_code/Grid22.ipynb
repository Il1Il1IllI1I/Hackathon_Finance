{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Check:  {'classes': array(['down', 'neutral', 'up'], dtype=object), 'encoded_labels': 레이블\n",
      "0    1357\n",
      "2     847\n",
      "1     719\n",
      "Name: count, dtype: int64}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 52}\n",
      "Best Score:  0.8778150158029698\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       407\n",
      "           1       0.78      0.82      0.80       216\n",
      "           2       0.89      0.91      0.90       254\n",
      "\n",
      "    accuracy                           0.89       877\n",
      "   macro avg       0.87      0.88      0.88       877\n",
      "weighted avg       0.89      0.89      0.89       877\n",
      "\n",
      "\n",
      "Scores:\n",
      "               Score\n",
      "Accuracy   0.890536\n",
      "Precision  0.893450\n",
      "Recall     0.890536\n",
      "F1 Score   0.891561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.890536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.893450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.890536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.891561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score\n",
       "Accuracy   0.890536\n",
       "Precision  0.893450\n",
       "Recall     0.890536\n",
       "F1 Score   0.891561"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1회\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "\n",
    "# 데이터 로딩\n",
    "file_path = 'real_ks200.csv'\n",
    "df = pd.read_csv(file_path, index_col=\"날짜\", encoding='utf-8')\n",
    "\n",
    "# 1. 레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "df['레이블'] = encoder.fit_transform(df['레이블'])\n",
    "\n",
    "# 인코딩 확인\n",
    "encoding_check = {\n",
    "    \"classes\": encoder.classes_,\n",
    "    \"encoded_labels\": df['레이블'].value_counts()\n",
    "}\n",
    "print(\"Encoding Check: \", encoding_check)\n",
    "\n",
    "# 2. 학습 데이터와 테스트 데이터 분리\n",
    "X = df.drop('레이블', axis=1)\n",
    "y = df['레이블']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# 3. GridSearchCV 설정 및 학습\n",
    "param_grid = {\n",
    "    'n_estimators': [50,51,52,53,54,55],\n",
    "    'max_depth': [None,1,2,3,4,5],\n",
    "    'min_samples_split': [2,3,4,5],\n",
    "    'min_samples_leaf': [1, 2,3, 4]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 최적 하이퍼파라미터 확인\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "\n",
    "# 5. 모델 평가 및 표 출력\n",
    "def evaluate_and_display_model(y_test, y_pred):\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 평가 메트릭을 데이터프레임으로 변환 및 출력\n",
    "    metrics_df = pd.DataFrame(metrics.values(), index=metrics.keys(), columns=['Score'])\n",
    "    print(\"\\nScores:\\n\", metrics_df)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# 6. 예측 및 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "evaluate_and_display_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Check:  {'classes': array(['down', 'neutral', 'up'], dtype=object), 'encoded_labels': 레이블\n",
      "0    1357\n",
      "2     847\n",
      "1     719\n",
      "Name: count, dtype: int64}\n",
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Score:  0.8778138231260064\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       407\n",
      "           1       0.78      0.82      0.80       216\n",
      "           2       0.89      0.92      0.90       254\n",
      "\n",
      "    accuracy                           0.89       877\n",
      "   macro avg       0.88      0.89      0.88       877\n",
      "weighted avg       0.90      0.89      0.89       877\n",
      "\n",
      "\n",
      "Scores:\n",
      "               Score\n",
      "Accuracy   0.892816\n",
      "Precision  0.895811\n",
      "Recall     0.892816\n",
      "F1 Score   0.893836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.892816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.895811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.892816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.893836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score\n",
       "Accuracy   0.892816\n",
       "Precision  0.895811\n",
       "Recall     0.892816\n",
       "F1 Score   0.893836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2회\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "\n",
    "# 데이터 로딩\n",
    "file_path = 'real_ks200.csv'\n",
    "df = pd.read_csv(file_path, index_col=\"날짜\", encoding='utf-8')\n",
    "\n",
    "# 1. 레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "df['레이블'] = encoder.fit_transform(df['레이블'])\n",
    "\n",
    "# 인코딩 확인\n",
    "encoding_check = {\n",
    "    \"classes\": encoder.classes_,\n",
    "    \"encoded_labels\": df['레이블'].value_counts()\n",
    "}\n",
    "print(\"Encoding Check: \", encoding_check)\n",
    "\n",
    "# 2. 학습 데이터와 테스트 데이터 분리\n",
    "X = df.drop('레이블', axis=1)\n",
    "y = df['레이블']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# 3. GridSearchCV 설정 및 학습\n",
    "param_grid = {\n",
    "    'n_estimators': [30, 40, 50, 60, 70],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 최적 하이퍼파라미터 확인\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "\n",
    "# 5. 모델 평가 및 표 출력\n",
    "def evaluate_and_display_model(y_test, y_pred):\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 평가 메트릭을 데이터프레임으로 변환 및 출력\n",
    "    metrics_df = pd.DataFrame(metrics.values(), index=metrics.keys(), columns=['Score'])\n",
    "    print(\"\\nScores:\\n\", metrics_df)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# 6. 예측 및 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "evaluate_and_display_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Check:  {'classes': array(['down', 'neutral', 'up'], dtype=object), 'encoded_labels': 레이블\n",
      "0    1357\n",
      "2     847\n",
      "1     719\n",
      "Name: count, dtype: int64}\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 55}\n",
      "Best Score:  0.8778150158029698\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       407\n",
      "           1       0.78      0.82      0.80       216\n",
      "           2       0.88      0.91      0.90       254\n",
      "\n",
      "    accuracy                           0.89       877\n",
      "   macro avg       0.87      0.88      0.88       877\n",
      "weighted avg       0.89      0.89      0.89       877\n",
      "\n",
      "\n",
      "Scores:\n",
      "               Score\n",
      "Accuracy   0.889396\n",
      "Precision  0.892652\n",
      "Recall     0.889396\n",
      "F1 Score   0.890542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.889396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.892652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.889396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.890542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score\n",
       "Accuracy   0.889396\n",
       "Precision  0.892652\n",
       "Recall     0.889396\n",
       "F1 Score   0.890542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3회\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "\n",
    "# 데이터 로딩\n",
    "file_path = 'real_ks200.csv'\n",
    "df = pd.read_csv(file_path, index_col=\"날짜\", encoding='utf-8')\n",
    "\n",
    "# 1. 레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "df['레이블'] = encoder.fit_transform(df['레이블'])\n",
    "\n",
    "# 인코딩 확인\n",
    "encoding_check = {\n",
    "    \"classes\": encoder.classes_,\n",
    "    \"encoded_labels\": df['레이블'].value_counts()\n",
    "}\n",
    "print(\"Encoding Check: \", encoding_check)\n",
    "\n",
    "# 2. 학습 데이터와 테스트 데이터 분리\n",
    "X = df.drop('레이블', axis=1)\n",
    "y = df['레이블']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# 3. GridSearchCV 설정 및 학습\n",
    "param_grid = {\n",
    "    'n_estimators': [45, 50, 55],\n",
    "    'max_depth': [None, 40, 50, 60],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. 최적 하이퍼파라미터 확인\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "\n",
    "# 5. 모델 평가 및 표 출력\n",
    "def evaluate_and_display_model(y_test, y_pred):\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 평가 메트릭을 데이터프레임으로 변환 및 출력\n",
    "    metrics_df = pd.DataFrame(metrics.values(), index=metrics.keys(), columns=['Score'])\n",
    "    print(\"\\nScores:\\n\", metrics_df)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# 6. 예측 및 평가\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "evaluate_and_display_model(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
